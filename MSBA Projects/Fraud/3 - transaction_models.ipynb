{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a wide variety of modeling algorithms for a binary classification problem. It reads a file created from a feature selection process that has a reasonably small number of good variables, and we know their order of multivariate importance because we used a proper wrapper method. We can explore # input variables, model algorithms and tune model hyperparameters. At the end we can select our favorite algorithm, run it again and build the final model performace score percentile tables.\n",
    "\n",
    "There's also a cell that allows us to step through hyperparamters for any particular model to examine how the model overfits as a hyparameter changes.\n",
    "\n",
    "Here we call the larger fraction population the goods and the smaller fraction the bads. This notebook was originally written for fraud detection but can be used for any binary classification. It uses detection rate as an appropriate measure of goodness.\n",
    "\n",
    "Rather than use a built-in CV, we do a \"manual CV\" by running each model multiple (nitermax) times and average the performance on the training (trn), testing (tst) and out of time (oot) data sets.\n",
    "\n",
    "Some of the ML algorithms are very fast and some are slow. Feel free to comment out any cells/models you want. At the bottom of the notebook you should select your final/best model and hyperparameters to run one time only and then make the business performance tables for that final model. Note once we've decided on the final model and hyperparameters we're allowed to make several trial runs of our final model train looking for a good performance on the testing data, as long as we don't make any changes to the model hyperparameters from our final choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to add: better calculation of FDR@3% when building a model using sampled training data. Right now I just approximate it by using the entire population trntst for a model built with sampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This will let you see all the particular library vertsions you have loaded\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97496, 22)\n",
      "CPU times: total: 203 ms\n",
      "Wall time: 600 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Cardnum_unique_count_for_card_state_3</th>\n",
       "      <th>Cardnum_unique_count_for_card_zip_3</th>\n",
       "      <th>Merchnum_desc_Zip_total_3</th>\n",
       "      <th>Cardnum_unique_count_for_Merchnum_3</th>\n",
       "      <th>Cardnum_actual/toal_1</th>\n",
       "      <th>Cardnum_unique_count_for_card_state_7</th>\n",
       "      <th>Cardnum_actual/max_0</th>\n",
       "      <th>Card_dow_unique_count_for_merch_state_1</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31.42</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>31.42</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>178.49</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>178.49</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>178.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cardnum_unique_count_for_card_state_1  Card_Merchdesc_State_total_7  \\\n",
       "0                                      1                          3.62   \n",
       "1                                      1                         31.42   \n",
       "2                                      1                        178.49   \n",
       "3                                      1                          3.62   \n",
       "4                                      1                          7.24   \n",
       "\n",
       "   Cardnum_count_1_by_30  Cardnum_max_14  Card_dow_vdratio_0by60  \\\n",
       "0               0.033333            3.62                0.000011   \n",
       "1               0.033333           31.42                0.000011   \n",
       "2               0.033333          178.49                0.000011   \n",
       "3               0.033333            3.62                0.000011   \n",
       "4               0.033333            3.62                0.016667   \n",
       "\n",
       "   Card_dow_vdratio_0by14  Merchnum_desc_State_total_3  \\\n",
       "0                0.000049                         3.62   \n",
       "1                0.000049                        31.42   \n",
       "2                0.000049                       178.49   \n",
       "3                0.000049                         3.62   \n",
       "4                0.071429                         7.24   \n",
       "\n",
       "   Card_Merchdesc_total_7  Card_dow_unique_count_for_merch_zip_7  \\\n",
       "0                    3.62                                      1   \n",
       "1                   31.42                                      1   \n",
       "2                  178.49                                      1   \n",
       "3                    3.62                                      1   \n",
       "4                    7.24                                      1   \n",
       "\n",
       "   Cardnum_actual/toal_0  ...  Cardnum_unique_count_for_card_state_3  \\\n",
       "0                    1.0  ...                                      1   \n",
       "1                    1.0  ...                                      1   \n",
       "2                    1.0  ...                                      1   \n",
       "3                    1.0  ...                                      1   \n",
       "4                    0.5  ...                                      1   \n",
       "\n",
       "   Cardnum_unique_count_for_card_zip_3  Merchnum_desc_Zip_total_3  \\\n",
       "0                                    1                       3.62   \n",
       "1                                    1                      31.42   \n",
       "2                                    1                     178.49   \n",
       "3                                    1                       3.62   \n",
       "4                                    1                       7.24   \n",
       "\n",
       "   Cardnum_unique_count_for_Merchnum_3  Cardnum_actual/toal_1  \\\n",
       "0                                    1                    1.0   \n",
       "1                                    1                    1.0   \n",
       "2                                    1                    1.0   \n",
       "3                                    1                    1.0   \n",
       "4                                    1                    0.5   \n",
       "\n",
       "   Cardnum_unique_count_for_card_state_7  Cardnum_actual/max_0  \\\n",
       "0                                      1                   1.0   \n",
       "1                                      1                   1.0   \n",
       "2                                      1                   1.0   \n",
       "3                                      1                   1.0   \n",
       "4                                      1                   1.0   \n",
       "\n",
       "   Card_dow_unique_count_for_merch_state_1  Recnum  Fraud  \n",
       "0                                        1       1      0  \n",
       "1                                        1       2      0  \n",
       "2                                        1       3      0  \n",
       "3                                        1       4      0  \n",
       "4                                        1       5      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars = pd.read_csv('vars_final.csv')\n",
    "print(vars.shape)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'Cardnum_unique_count_for_card_state_1',\n",
       " 'Card_Merchdesc_State_total_7',\n",
       " 'Cardnum_count_1_by_30',\n",
       " 'Cardnum_max_14',\n",
       " 'Card_dow_vdratio_0by60',\n",
       " 'Card_dow_vdratio_0by14',\n",
       " 'Merchnum_desc_State_total_3',\n",
       " 'Card_Merchdesc_total_7',\n",
       " 'Card_dow_unique_count_for_merch_zip_7',\n",
       " 'Cardnum_actual/toal_0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the number of variables desired here, and set the names of the y and record label properly\n",
    "NVARS = 10\n",
    "\n",
    "# vars.rename(columns={'record':'Recnum'},inplace=True)\n",
    "# vars.rename(columns={'fraud_label':'Fraud'},inplace=True)\n",
    "detect_rate = .03\n",
    "numvars = min(NVARS,len(vars)-2)\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(vars.columns[i])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.42</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>31.42</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178.49</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>178.49</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  Cardnum_unique_count_for_card_state_1  \\\n",
       "0       1      0                                      1   \n",
       "1       2      0                                      1   \n",
       "2       3      0                                      1   \n",
       "3       4      0                                      1   \n",
       "4       5      0                                      1   \n",
       "\n",
       "   Card_Merchdesc_State_total_7  Cardnum_count_1_by_30  Cardnum_max_14  \\\n",
       "0                          3.62               0.033333            3.62   \n",
       "1                         31.42               0.033333           31.42   \n",
       "2                        178.49               0.033333          178.49   \n",
       "3                          3.62               0.033333            3.62   \n",
       "4                          7.24               0.033333            3.62   \n",
       "\n",
       "   Card_dow_vdratio_0by60  Card_dow_vdratio_0by14  \\\n",
       "0                0.000011                0.000049   \n",
       "1                0.000011                0.000049   \n",
       "2                0.000011                0.000049   \n",
       "3                0.000011                0.000049   \n",
       "4                0.016667                0.071429   \n",
       "\n",
       "   Merchnum_desc_State_total_3  Card_Merchdesc_total_7  \\\n",
       "0                         3.62                    3.62   \n",
       "1                        31.42                   31.42   \n",
       "2                       178.49                  178.49   \n",
       "3                         3.62                    3.62   \n",
       "4                         7.24                    7.24   \n",
       "\n",
       "   Card_dow_unique_count_for_merch_zip_7  Cardnum_actual/toal_0  \n",
       "0                                      1                    1.0  \n",
       "1                                      1                    1.0  \n",
       "2                                      1                    1.0  \n",
       "3                                      1                    1.0  \n",
       "4                                      1                    0.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.filter(final_vars_list,axis=1)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97496, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud rate in data is 0.020995733158283417\n"
     ]
    }
   ],
   "source": [
    "print(\"fraud rate in data is\",vars['Fraud'].sum()/len(vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.42</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>31.42</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178.49</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>178.49</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230.32</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>230.32</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.11</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>62.11</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.86</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  Cardnum_unique_count_for_card_state_1  \\\n",
       "0       1      0                                      1   \n",
       "1       2      0                                      1   \n",
       "2       3      0                                      1   \n",
       "3       4      0                                      1   \n",
       "4       5      0                                      1   \n",
       "5       6      0                                      1   \n",
       "6       7      0                                      1   \n",
       "7       8      0                                      1   \n",
       "8       9      0                                      1   \n",
       "9      10      0                                      1   \n",
       "\n",
       "   Card_Merchdesc_State_total_7  Cardnum_count_1_by_30  Cardnum_max_14  \\\n",
       "0                          3.62               0.033333            3.62   \n",
       "1                         31.42               0.033333           31.42   \n",
       "2                        178.49               0.033333          178.49   \n",
       "3                          3.62               0.033333            3.62   \n",
       "4                          7.24               0.033333            3.62   \n",
       "5                          3.67               0.033333            3.67   \n",
       "6                          3.62               0.033333            3.62   \n",
       "7                        230.32               0.033333          230.32   \n",
       "8                         62.11               0.033333           62.11   \n",
       "9                         10.86               0.033333            3.62   \n",
       "\n",
       "   Card_dow_vdratio_0by60  Card_dow_vdratio_0by14  \\\n",
       "0                0.000011                0.000049   \n",
       "1                0.000011                0.000049   \n",
       "2                0.000011                0.000049   \n",
       "3                0.000011                0.000049   \n",
       "4                0.016667                0.071429   \n",
       "5                0.000011                0.000049   \n",
       "6                0.000011                0.000049   \n",
       "7                0.000011                0.000049   \n",
       "8                0.000011                0.000049   \n",
       "9                0.016667                0.071429   \n",
       "\n",
       "   Merchnum_desc_State_total_3  Card_Merchdesc_total_7  \\\n",
       "0                         3.62                    3.62   \n",
       "1                        31.42                   31.42   \n",
       "2                       178.49                  178.49   \n",
       "3                         3.62                    3.62   \n",
       "4                         7.24                    7.24   \n",
       "5                         3.67                    3.67   \n",
       "6                         7.24                    3.62   \n",
       "7                       230.32                  230.32   \n",
       "8                        62.11                   62.11   \n",
       "9                        10.86                   10.86   \n",
       "\n",
       "   Card_dow_unique_count_for_merch_zip_7  Cardnum_actual/toal_0  \n",
       "0                                      1               1.000000  \n",
       "1                                      1               1.000000  \n",
       "2                                      1               1.000000  \n",
       "3                                      1               1.000000  \n",
       "4                                      1               0.500000  \n",
       "5                                      1               1.000000  \n",
       "6                                      1               1.000000  \n",
       "7                                      1               1.000000  \n",
       "8                                      1               1.000000  \n",
       "9                                      1               0.333333  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97496, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48915.137247</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>1.724266</td>\n",
       "      <td>676.571639</td>\n",
       "      <td>0.008823</td>\n",
       "      <td>1194.385741</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>1413.472998</td>\n",
       "      <td>676.717953</td>\n",
       "      <td>1.892016</td>\n",
       "      <td>0.765940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28262.212670</td>\n",
       "      <td>0.143371</td>\n",
       "      <td>1.568565</td>\n",
       "      <td>4074.921736</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>1856.894526</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>5123.221915</td>\n",
       "      <td>4074.945381</td>\n",
       "      <td>1.874101</td>\n",
       "      <td>0.355093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24428.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>99.900000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48916.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>801.660000</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>356.450000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73402.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>1743.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>1325.600000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97852.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>307302.580000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Recnum         Fraud  Cardnum_unique_count_for_card_state_1  \\\n",
       "count  97496.000000  97496.000000                           97496.000000   \n",
       "mean   48915.137247      0.020996                               1.724266   \n",
       "std    28262.212670      0.143371                               1.568565   \n",
       "min        1.000000      0.000000                               1.000000   \n",
       "25%    24428.750000      0.000000                               1.000000   \n",
       "50%    48916.000000      0.000000                               1.000000   \n",
       "75%    73402.250000      0.000000                               2.000000   \n",
       "max    97852.000000      1.000000                              21.000000   \n",
       "\n",
       "       Card_Merchdesc_State_total_7  Cardnum_count_1_by_30  Cardnum_max_14  \\\n",
       "count                  97496.000000           97496.000000    97496.000000   \n",
       "mean                     676.571639               0.008823     1194.385741   \n",
       "std                     4074.921736               0.008372     1856.894526   \n",
       "min                        0.010000               0.000078        0.140000   \n",
       "25%                       52.500000               0.003226      307.000000   \n",
       "50%                      189.000000               0.005556      801.660000   \n",
       "75%                      590.000000               0.011111     1743.000000   \n",
       "max                   306633.410000               0.033333    47900.000000   \n",
       "\n",
       "       Card_dow_vdratio_0by60  Card_dow_vdratio_0by14  \\\n",
       "count            97496.000000            97496.000000   \n",
       "mean                 0.003231                0.020482   \n",
       "std                  0.004996                0.026914   \n",
       "min                  0.000007                0.000039   \n",
       "25%                  0.000152                0.001587   \n",
       "50%                  0.000370                0.002976   \n",
       "75%                  0.004762                0.042857   \n",
       "max                  0.016667                0.071429   \n",
       "\n",
       "       Merchnum_desc_State_total_3  Card_Merchdesc_total_7  \\\n",
       "count                 97496.000000            97496.000000   \n",
       "mean                   1413.472998              676.717953   \n",
       "std                    5123.221915             4074.945381   \n",
       "min                       0.010000                0.010000   \n",
       "25%                      99.900000               52.500000   \n",
       "50%                     356.450000              189.000000   \n",
       "75%                    1325.600000              590.000000   \n",
       "max                  307302.580000           306633.410000   \n",
       "\n",
       "       Card_dow_unique_count_for_merch_zip_7  Cardnum_actual/toal_0  \n",
       "count                           97496.000000           97496.000000  \n",
       "mean                                1.892016               0.765940  \n",
       "std                                 1.874101               0.355093  \n",
       "min                                 1.000000               0.000014  \n",
       "25%                                 1.000000               0.500000  \n",
       "50%                                 1.000000               1.000000  \n",
       "75%                                 2.000000               1.000000  \n",
       "max                                38.000000               1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84935</th>\n",
       "      <td>85265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174.61</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>225.00</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>174.61</td>\n",
       "      <td>174.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84936</th>\n",
       "      <td>85266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>395.00</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>53.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84937</th>\n",
       "      <td>85267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>531.25</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84938</th>\n",
       "      <td>85268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97.17</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>395.04</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>97.17</td>\n",
       "      <td>97.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84939</th>\n",
       "      <td>85269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84940</th>\n",
       "      <td>85270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.00</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>170.00</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>170.00</td>\n",
       "      <td>170.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84941</th>\n",
       "      <td>85271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>250.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84942</th>\n",
       "      <td>85272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>103.60</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84943</th>\n",
       "      <td>85273</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300.00</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>2105.00</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84944</th>\n",
       "      <td>85274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>133.20</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>268.20</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>133.20</td>\n",
       "      <td>133.20</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recnum  Fraud  Cardnum_unique_count_for_card_state_1  \\\n",
       "84935   85265      0                                      1   \n",
       "84936   85266      0                                      1   \n",
       "84937   85267      0                                      1   \n",
       "84938   85268      0                                      1   \n",
       "84939   85269      0                                      1   \n",
       "84940   85270      0                                      1   \n",
       "84941   85271      0                                      1   \n",
       "84942   85272      0                                      1   \n",
       "84943   85273      0                                      1   \n",
       "84944   85274      0                                      1   \n",
       "\n",
       "       Card_Merchdesc_State_total_7  Cardnum_count_1_by_30  Cardnum_max_14  \\\n",
       "84935                        174.61               0.016667          225.00   \n",
       "84936                         53.00               0.002778          395.00   \n",
       "84937                         25.00               0.004762          531.25   \n",
       "84938                         97.17               0.004762          395.04   \n",
       "84939                          6.51               0.016667            6.51   \n",
       "84940                        170.00               0.016667          170.00   \n",
       "84941                        250.00               0.002564          250.00   \n",
       "84942                         15.00               0.016667          103.60   \n",
       "84943                        300.00               0.006667         2105.00   \n",
       "84944                        133.20               0.002564          268.20   \n",
       "\n",
       "       Card_dow_vdratio_0by60  Card_dow_vdratio_0by14  \\\n",
       "84935                0.000074                0.000317   \n",
       "84936                0.000278                0.001190   \n",
       "84937                0.000417                0.002976   \n",
       "84938                0.000194                0.001661   \n",
       "84939                0.000167                0.001429   \n",
       "84940                0.000260                0.001116   \n",
       "84941                0.000149                0.001786   \n",
       "84942                0.000167                0.001429   \n",
       "84943                0.000024                0.001984   \n",
       "84944                0.001042                0.004464   \n",
       "\n",
       "       Merchnum_desc_State_total_3  Card_Merchdesc_total_7  \\\n",
       "84935                       174.61                  174.61   \n",
       "84936                        53.00                   53.00   \n",
       "84937                        25.00                   25.00   \n",
       "84938                        97.17                   97.17   \n",
       "84939                         6.51                    6.51   \n",
       "84940                       170.00                  170.00   \n",
       "84941                       250.00                  250.00   \n",
       "84942                        15.00                   15.00   \n",
       "84943                       300.00                  300.00   \n",
       "84944                       133.20                  133.20   \n",
       "\n",
       "       Card_dow_unique_count_for_merch_zip_7  Cardnum_actual/toal_0  \n",
       "84935                                      1                    1.0  \n",
       "84936                                      1                    1.0  \n",
       "84937                                      2                    1.0  \n",
       "84938                                      1                    1.0  \n",
       "84939                                      1                    1.0  \n",
       "84940                                      1                    1.0  \n",
       "84941                                      2                    1.0  \n",
       "84942                                      1                    1.0  \n",
       "84943                                      1                    1.0  \n",
       "84944                                      2                    1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the row i vars that corresponds to 11/1 for the OOT\n",
    "test = vars[vars['Recnum'] > 85264]\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "      <td>97496.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.724266</td>\n",
       "      <td>676.571639</td>\n",
       "      <td>0.008823</td>\n",
       "      <td>1194.385741</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>1413.472998</td>\n",
       "      <td>676.717953</td>\n",
       "      <td>1.892016</td>\n",
       "      <td>0.765940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.568565</td>\n",
       "      <td>4074.921736</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>1856.894526</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>5123.221915</td>\n",
       "      <td>4074.945381</td>\n",
       "      <td>1.874101</td>\n",
       "      <td>0.355093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>99.900000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>801.660000</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>356.450000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>1743.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>1325.600000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>307302.580000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cardnum_unique_count_for_card_state_1  Card_Merchdesc_State_total_7  \\\n",
       "count                           97496.000000                  97496.000000   \n",
       "mean                                1.724266                    676.571639   \n",
       "std                                 1.568565                   4074.921736   \n",
       "min                                 1.000000                      0.010000   \n",
       "25%                                 1.000000                     52.500000   \n",
       "50%                                 1.000000                    189.000000   \n",
       "75%                                 2.000000                    590.000000   \n",
       "max                                21.000000                 306633.410000   \n",
       "\n",
       "       Cardnum_count_1_by_30  Cardnum_max_14  Card_dow_vdratio_0by60  \\\n",
       "count           97496.000000    97496.000000            97496.000000   \n",
       "mean                0.008823     1194.385741                0.003231   \n",
       "std                 0.008372     1856.894526                0.004996   \n",
       "min                 0.000078        0.140000                0.000007   \n",
       "25%                 0.003226      307.000000                0.000152   \n",
       "50%                 0.005556      801.660000                0.000370   \n",
       "75%                 0.011111     1743.000000                0.004762   \n",
       "max                 0.033333    47900.000000                0.016667   \n",
       "\n",
       "       Card_dow_vdratio_0by14  Merchnum_desc_State_total_3  \\\n",
       "count            97496.000000                 97496.000000   \n",
       "mean                 0.020482                  1413.472998   \n",
       "std                  0.026914                  5123.221915   \n",
       "min                  0.000039                     0.010000   \n",
       "25%                  0.001587                    99.900000   \n",
       "50%                  0.002976                   356.450000   \n",
       "75%                  0.042857                  1325.600000   \n",
       "max                  0.071429                307302.580000   \n",
       "\n",
       "       Card_Merchdesc_total_7  Card_dow_unique_count_for_merch_zip_7  \\\n",
       "count            97496.000000                           97496.000000   \n",
       "mean               676.717953                               1.892016   \n",
       "std               4074.945381                               1.874101   \n",
       "min                  0.010000                               1.000000   \n",
       "25%                 52.500000                               1.000000   \n",
       "50%                189.000000                               1.000000   \n",
       "75%                590.000000                               2.000000   \n",
       "max             306633.410000                              38.000000   \n",
       "\n",
       "       Cardnum_actual/toal_0  \n",
       "count           97496.000000  \n",
       "mean                0.765940  \n",
       "std                 0.355093  \n",
       "min                 0.000014  \n",
       "25%                 0.500000  \n",
       "50%                 1.000000  \n",
       "75%                 1.000000  \n",
       "max                 1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier treatment: use this to limit variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "      <td>9.749600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.049460e-17</td>\n",
       "      <td>-7.287917e-18</td>\n",
       "      <td>-5.830333e-19</td>\n",
       "      <td>7.870950e-18</td>\n",
       "      <td>-1.472159e-17</td>\n",
       "      <td>1.224370e-17</td>\n",
       "      <td>-1.166067e-18</td>\n",
       "      <td>-1.049460e-17</td>\n",
       "      <td>3.119228e-17</td>\n",
       "      <td>-4.372750e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.651796e-01</td>\n",
       "      <td>-3.346282e-01</td>\n",
       "      <td>-1.044444e+00</td>\n",
       "      <td>-7.194261e-01</td>\n",
       "      <td>-6.452996e-01</td>\n",
       "      <td>-7.595529e-01</td>\n",
       "      <td>-4.318529e-01</td>\n",
       "      <td>-3.346955e-01</td>\n",
       "      <td>-5.031954e-01</td>\n",
       "      <td>-2.156969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.651796e-01</td>\n",
       "      <td>-3.065413e-01</td>\n",
       "      <td>-6.685133e-01</td>\n",
       "      <td>-5.318162e-01</td>\n",
       "      <td>-6.163864e-01</td>\n",
       "      <td>-7.020303e-01</td>\n",
       "      <td>-3.999404e-01</td>\n",
       "      <td>-3.066096e-01</td>\n",
       "      <td>-5.031954e-01</td>\n",
       "      <td>-7.489285e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.651796e-01</td>\n",
       "      <td>-2.335016e-01</td>\n",
       "      <td>-3.902418e-01</td>\n",
       "      <td>-2.293881e-01</td>\n",
       "      <td>-5.725765e-01</td>\n",
       "      <td>-6.504263e-01</td>\n",
       "      <td>-3.179788e-01</td>\n",
       "      <td>-2.335723e-01</td>\n",
       "      <td>-5.031954e-01</td>\n",
       "      <td>6.591519e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.782986e-01</td>\n",
       "      <td>-1.893059e-02</td>\n",
       "      <td>2.733285e-01</td>\n",
       "      <td>3.461339e-01</td>\n",
       "      <td>3.065090e-01</td>\n",
       "      <td>8.313456e-01</td>\n",
       "      <td>-8.358364e-03</td>\n",
       "      <td>-1.900840e-02</td>\n",
       "      <td>6.696772e-02</td>\n",
       "      <td>6.591519e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.009425e+01</td>\n",
       "      <td>2.183188e+01</td>\n",
       "      <td>2.927610e+00</td>\n",
       "      <td>1.136351e+01</td>\n",
       "      <td>2.689572e+00</td>\n",
       "      <td>1.892914e+00</td>\n",
       "      <td>1.638719e+01</td>\n",
       "      <td>2.183128e+01</td>\n",
       "      <td>1.069083e+01</td>\n",
       "      <td>6.591519e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cardnum_unique_count_for_card_state_1  Card_Merchdesc_State_total_7  \\\n",
       "count                           9.749600e+04                  9.749600e+04   \n",
       "mean                            1.049460e-17                 -7.287917e-18   \n",
       "std                             1.000000e+00                  1.000000e+00   \n",
       "min                            -4.651796e-01                 -3.346282e-01   \n",
       "25%                            -4.651796e-01                 -3.065413e-01   \n",
       "50%                            -4.651796e-01                 -2.335016e-01   \n",
       "75%                             1.782986e-01                 -1.893059e-02   \n",
       "max                             1.009425e+01                  2.183188e+01   \n",
       "\n",
       "       Cardnum_count_1_by_30  Cardnum_max_14  Card_dow_vdratio_0by60  \\\n",
       "count           9.749600e+04    9.749600e+04            9.749600e+04   \n",
       "mean           -5.830333e-19    7.870950e-18           -1.472159e-17   \n",
       "std             1.000000e+00    1.000000e+00            1.000000e+00   \n",
       "min            -1.044444e+00   -7.194261e-01           -6.452996e-01   \n",
       "25%            -6.685133e-01   -5.318162e-01           -6.163864e-01   \n",
       "50%            -3.902418e-01   -2.293881e-01           -5.725765e-01   \n",
       "75%             2.733285e-01    3.461339e-01            3.065090e-01   \n",
       "max             2.927610e+00    1.136351e+01            2.689572e+00   \n",
       "\n",
       "       Card_dow_vdratio_0by14  Merchnum_desc_State_total_3  \\\n",
       "count            9.749600e+04                 9.749600e+04   \n",
       "mean             1.224370e-17                -1.166067e-18   \n",
       "std              1.000000e+00                 1.000000e+00   \n",
       "min             -7.595529e-01                -4.318529e-01   \n",
       "25%             -7.020303e-01                -3.999404e-01   \n",
       "50%             -6.504263e-01                -3.179788e-01   \n",
       "75%              8.313456e-01                -8.358364e-03   \n",
       "max              1.892914e+00                 1.638719e+01   \n",
       "\n",
       "       Card_Merchdesc_total_7  Card_dow_unique_count_for_merch_zip_7  \\\n",
       "count            9.749600e+04                           9.749600e+04   \n",
       "mean            -1.049460e-17                           3.119228e-17   \n",
       "std              1.000000e+00                           1.000000e+00   \n",
       "min             -3.346955e-01                          -5.031954e-01   \n",
       "25%             -3.066096e-01                          -5.031954e-01   \n",
       "50%             -2.335723e-01                          -5.031954e-01   \n",
       "75%             -1.900840e-02                           6.696772e-02   \n",
       "max              2.183128e+01                           1.069083e+01   \n",
       "\n",
       "       Cardnum_actual/toal_0  \n",
       "count           9.749600e+04  \n",
       "mean           -4.372750e-17  \n",
       "std             1.000000e+00  \n",
       "min            -2.156969e+00  \n",
       "25%            -7.489285e-01  \n",
       "50%             6.591519e-01  \n",
       "75%             6.591519e-01  \n",
       "max             6.591519e-01  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values, then rescale\n",
    "X.clip(-1*Clip,Clip,inplace=True)\n",
    "X = (X - X.mean()) / X.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud    297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate data into modeling (traintest) and out of time. Here I'm using the record number to do this separation.\n",
    "# you need to change this OOT record number to whatever is appropriate for your data\n",
    "oot_recnum = 85264\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]\n",
    "Y_oot.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_trntst.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trntst_save = X_trntst.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components = .999, svd_solver = 'full')\n",
    "pca.fit(X_trntst)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of components minus 1')\n",
    "plt.ylabel('PC variance')\n",
    "plt.xticks(np.arange(0, len(X_trntst.columns), step=2))\n",
    "plt.axhline(y=0,xmin=0,xmax=len(X_trntst.columns))\n",
    "X_trntst = X_trntst_save.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.233799</td>\n",
       "      <td>-0.146768</td>\n",
       "      <td>-1.261853</td>\n",
       "      <td>2.670857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.217854</td>\n",
       "      <td>-0.125352</td>\n",
       "      <td>-1.258504</td>\n",
       "      <td>2.668163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.133501</td>\n",
       "      <td>-0.012059</td>\n",
       "      <td>-1.240786</td>\n",
       "      <td>2.653911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.233799</td>\n",
       "      <td>-0.146768</td>\n",
       "      <td>-1.261853</td>\n",
       "      <td>2.670857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.747323</td>\n",
       "      <td>-2.263030</td>\n",
       "      <td>-3.108010</td>\n",
       "      <td>1.383728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4\n",
       "0 -1.233799 -0.146768 -1.261853  2.670857\n",
       "1 -1.217854 -0.125352 -1.258504  2.668163\n",
       "2 -1.133501 -0.012059 -1.240786  2.653911\n",
       "3 -1.233799 -0.146768 -1.261853  2.670857\n",
       "4  1.747323 -2.263030 -3.108010  1.383728"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We look at the above picture, select how many PCs we want to keep, and then redo the PCA with just this many PCs\n",
    "pca = PCA(n_components = 4, svd_solver = 'full')\n",
    "princ_comps = pca.fit_transform(X_trntst)\n",
    "X_trntst_pca = pd.DataFrame(princ_comps, columns = ['PC' + str(i) for i in range(1, pca.n_components_+1)])\n",
    "X_trntst_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85264</th>\n",
       "      <td>0.474670</td>\n",
       "      <td>-0.992169</td>\n",
       "      <td>1.246312</td>\n",
       "      <td>-0.399651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85265</th>\n",
       "      <td>1.595099</td>\n",
       "      <td>-2.099471</td>\n",
       "      <td>-2.338872</td>\n",
       "      <td>1.408899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85266</th>\n",
       "      <td>-0.171959</td>\n",
       "      <td>1.949085</td>\n",
       "      <td>-0.161534</td>\n",
       "      <td>0.375554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85267</th>\n",
       "      <td>-1.073062</td>\n",
       "      <td>0.429463</td>\n",
       "      <td>0.660778</td>\n",
       "      <td>-0.213056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85268</th>\n",
       "      <td>-1.238510</td>\n",
       "      <td>0.678886</td>\n",
       "      <td>-0.019114</td>\n",
       "      <td>-0.217072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3       PC4\n",
       "85264  0.474670 -0.992169  1.246312 -0.399651\n",
       "85265  1.595099 -2.099471 -2.338872  1.408899\n",
       "85266 -0.171959  1.949085 -0.161534  0.375554\n",
       "85267 -1.073062  0.429463  0.660778 -0.213056\n",
       "85268 -1.238510  0.678886 -0.019114 -0.217072"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "princ_comps = pca.transform(X_oot)\n",
    "X_oot_orig_pca = pd.DataFrame(princ_comps, columns = ['PC' + str(i) for i in range(1, pca.n_components_+1)],index=X_oot.index)\n",
    "X_oot_orig_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardnum_unique_count_for_card_state_1</th>\n",
       "      <th>Card_Merchdesc_State_total_7</th>\n",
       "      <th>Cardnum_count_1_by_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Card_dow_vdratio_0by60</th>\n",
       "      <th>Card_dow_vdratio_0by14</th>\n",
       "      <th>Merchnum_desc_State_total_3</th>\n",
       "      <th>Card_Merchdesc_total_7</th>\n",
       "      <th>Card_dow_unique_count_for_merch_zip_7</th>\n",
       "      <th>Cardnum_actual/toal_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "      <td>85264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>-0.013411</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>-0.007076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.007299</td>\n",
       "      <td>1.029148</td>\n",
       "      <td>0.996083</td>\n",
       "      <td>0.988241</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.038863</td>\n",
       "      <td>1.029151</td>\n",
       "      <td>1.014974</td>\n",
       "      <td>1.003383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.465180</td>\n",
       "      <td>-0.334628</td>\n",
       "      <td>-1.044444</td>\n",
       "      <td>-0.719426</td>\n",
       "      <td>-0.645300</td>\n",
       "      <td>-0.759504</td>\n",
       "      <td>-0.431853</td>\n",
       "      <td>-0.334696</td>\n",
       "      <td>-0.503195</td>\n",
       "      <td>-2.156969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.465180</td>\n",
       "      <td>-0.307403</td>\n",
       "      <td>-0.680554</td>\n",
       "      <td>-0.528478</td>\n",
       "      <td>-0.616386</td>\n",
       "      <td>-0.699287</td>\n",
       "      <td>-0.400153</td>\n",
       "      <td>-0.307467</td>\n",
       "      <td>-0.503195</td>\n",
       "      <td>-0.748928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.465180</td>\n",
       "      <td>-0.234920</td>\n",
       "      <td>-0.390242</td>\n",
       "      <td>-0.220376</td>\n",
       "      <td>-0.572577</td>\n",
       "      <td>-0.640374</td>\n",
       "      <td>-0.318782</td>\n",
       "      <td>-0.234966</td>\n",
       "      <td>-0.503195</td>\n",
       "      <td>0.659152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.178299</td>\n",
       "      <td>-0.019391</td>\n",
       "      <td>0.273329</td>\n",
       "      <td>0.354082</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>0.831346</td>\n",
       "      <td>-0.004259</td>\n",
       "      <td>-0.019273</td>\n",
       "      <td>0.066968</td>\n",
       "      <td>0.659152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.094246</td>\n",
       "      <td>21.831881</td>\n",
       "      <td>2.927610</td>\n",
       "      <td>11.363510</td>\n",
       "      <td>2.689572</td>\n",
       "      <td>1.892914</td>\n",
       "      <td>16.387194</td>\n",
       "      <td>21.831284</td>\n",
       "      <td>10.690830</td>\n",
       "      <td>0.659152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cardnum_unique_count_for_card_state_1  Card_Merchdesc_State_total_7  \\\n",
       "count                           85264.000000                  85264.000000   \n",
       "mean                                0.004006                      0.002794   \n",
       "std                                 1.007299                      1.029148   \n",
       "min                                -0.465180                     -0.334628   \n",
       "25%                                -0.465180                     -0.307403   \n",
       "50%                                -0.465180                     -0.234920   \n",
       "75%                                 0.178299                     -0.019391   \n",
       "max                                10.094246                     21.831881   \n",
       "\n",
       "       Cardnum_count_1_by_30  Cardnum_max_14  Card_dow_vdratio_0by60  \\\n",
       "count           85264.000000    85264.000000            85264.000000   \n",
       "mean               -0.013411        0.003866                0.000122   \n",
       "std                 0.996083        0.988241                0.999618   \n",
       "min                -1.044444       -0.719426               -0.645300   \n",
       "25%                -0.680554       -0.528478               -0.616386   \n",
       "50%                -0.390242       -0.220376               -0.572577   \n",
       "75%                 0.273329        0.354082                0.306509   \n",
       "max                 2.927610       11.363510                2.689572   \n",
       "\n",
       "       Card_dow_vdratio_0by14  Merchnum_desc_State_total_3  \\\n",
       "count            85264.000000                 85264.000000   \n",
       "mean                 0.003494                     0.011369   \n",
       "std                  1.000623                     1.038863   \n",
       "min                 -0.759504                    -0.431853   \n",
       "25%                 -0.699287                    -0.400153   \n",
       "50%                 -0.640374                    -0.318782   \n",
       "75%                  0.831346                    -0.004259   \n",
       "max                  1.892914                    16.387194   \n",
       "\n",
       "       Card_Merchdesc_total_7  Card_dow_unique_count_for_merch_zip_7  \\\n",
       "count            85264.000000                           85264.000000   \n",
       "mean                 0.002805                               0.004227   \n",
       "std                  1.029151                               1.014974   \n",
       "min                 -0.334696                              -0.503195   \n",
       "25%                 -0.307467                              -0.503195   \n",
       "50%                 -0.234966                              -0.503195   \n",
       "75%                 -0.019273                               0.066968   \n",
       "max                 21.831284                              10.690830   \n",
       "\n",
       "       Cardnum_actual/toal_0  \n",
       "count           85264.000000  \n",
       "mean               -0.007076  \n",
       "std                 1.003383  \n",
       "min                -2.156969  \n",
       "25%                -0.748928  \n",
       "50%                 0.659152  \n",
       "75%                 0.659152  \n",
       "max                 0.659152  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trntst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12232.000000</td>\n",
       "      <td>12232.000000</td>\n",
       "      <td>12232.000000</td>\n",
       "      <td>12232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.084839</td>\n",
       "      <td>-0.037318</td>\n",
       "      <td>-0.060807</td>\n",
       "      <td>0.090004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.689561</td>\n",
       "      <td>1.360119</td>\n",
       "      <td>1.158176</td>\n",
       "      <td>0.966594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.696425</td>\n",
       "      <td>-6.345955</td>\n",
       "      <td>-4.842932</td>\n",
       "      <td>-4.632864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.295068</td>\n",
       "      <td>-0.697445</td>\n",
       "      <td>-0.557728</td>\n",
       "      <td>-0.438803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.893845</td>\n",
       "      <td>0.194860</td>\n",
       "      <td>-0.029108</td>\n",
       "      <td>-0.109650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.045609</td>\n",
       "      <td>0.502024</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.438306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.527572</td>\n",
       "      <td>29.137615</td>\n",
       "      <td>9.748135</td>\n",
       "      <td>5.452739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1           PC2           PC3           PC4\n",
       "count  12232.000000  12232.000000  12232.000000  12232.000000\n",
       "mean      -0.084839     -0.037318     -0.060807      0.090004\n",
       "std        1.689561      1.360119      1.158176      0.966594\n",
       "min       -1.696425     -6.345955     -4.842932     -4.632864\n",
       "25%       -1.295068     -0.697445     -0.557728     -0.438803\n",
       "50%       -0.893845      0.194860     -0.029108     -0.109650\n",
       "75%        1.045609      0.502024      0.389831      0.438306\n",
       "max       21.527572     29.137615      9.748135      5.452739"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oot_orig_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zscale the PCs\n",
    "mean = X_trntst_pca.mean()\n",
    "stdev = X_trntst_pca.std()\n",
    "X_trntst_pca = (X_trntst_pca - mean)/stdev\n",
    "X_oot_orig_pca = (X_oot_orig_pca - mean)/stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.526400e+04</td>\n",
       "      <td>8.526400e+04</td>\n",
       "      <td>8.526400e+04</td>\n",
       "      <td>8.526400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.533354e-17</td>\n",
       "      <td>-8.000106e-18</td>\n",
       "      <td>-8.666781e-18</td>\n",
       "      <td>8.666781e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.533328e-01</td>\n",
       "      <td>-4.052689e+00</td>\n",
       "      <td>-5.196134e+00</td>\n",
       "      <td>-4.686439e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.921927e-01</td>\n",
       "      <td>-4.952199e-01</td>\n",
       "      <td>-4.252566e-01</td>\n",
       "      <td>-5.479011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.120381e-01</td>\n",
       "      <td>1.169866e-01</td>\n",
       "      <td>1.252057e-02</td>\n",
       "      <td>-1.881926e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.904588e-01</td>\n",
       "      <td>3.207532e-01</td>\n",
       "      <td>3.698016e-01</td>\n",
       "      <td>3.265700e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.341726e+01</td>\n",
       "      <td>1.839694e+01</td>\n",
       "      <td>1.136849e+01</td>\n",
       "      <td>6.388562e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1           PC2           PC3           PC4\n",
       "count  8.526400e+04  8.526400e+04  8.526400e+04  8.526400e+04\n",
       "mean   1.533354e-17 -8.000106e-18 -8.666781e-18  8.666781e-18\n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min   -9.533328e-01 -4.052689e+00 -5.196134e+00 -4.686439e+00\n",
       "25%   -6.921927e-01 -4.952199e-01 -4.252566e-01 -5.479011e-01\n",
       "50%   -4.120381e-01  1.169866e-01  1.252057e-02 -1.881926e-01\n",
       "75%    5.904588e-01  3.207532e-01  3.698016e-01  3.265700e-01\n",
       "max    1.341726e+01  1.839694e+01  1.136849e+01  6.388562e+00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trntst_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12232.000000</td>\n",
       "      <td>12232.000000</td>\n",
       "      <td>12232.000000</td>\n",
       "      <td>12232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.046605</td>\n",
       "      <td>-0.022527</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.092140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.928131</td>\n",
       "      <td>0.821052</td>\n",
       "      <td>0.945546</td>\n",
       "      <td>0.989529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.931901</td>\n",
       "      <td>-3.830809</td>\n",
       "      <td>-3.953814</td>\n",
       "      <td>-4.742789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.711423</td>\n",
       "      <td>-0.421021</td>\n",
       "      <td>-0.455334</td>\n",
       "      <td>-0.449215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.491018</td>\n",
       "      <td>0.117629</td>\n",
       "      <td>-0.023764</td>\n",
       "      <td>-0.112251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.574387</td>\n",
       "      <td>0.303053</td>\n",
       "      <td>0.318262</td>\n",
       "      <td>0.448706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.825793</td>\n",
       "      <td>17.589258</td>\n",
       "      <td>7.958466</td>\n",
       "      <td>5.582118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1           PC2           PC3           PC4\n",
       "count  12232.000000  12232.000000  12232.000000  12232.000000\n",
       "mean      -0.046605     -0.022527     -0.049643      0.092140\n",
       "std        0.928131      0.821052      0.945546      0.989529\n",
       "min       -0.931901     -3.830809     -3.953814     -4.742789\n",
       "25%       -0.711423     -0.421021     -0.455334     -0.449215\n",
       "50%       -0.491018      0.117629     -0.023764     -0.112251\n",
       "75%        0.574387      0.303053      0.318262      0.448706\n",
       "max       11.825793     17.589258      7.958466      5.582118"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oot_orig_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85264, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trntst_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12232, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oot_orig_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample the larger class if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020524488647025708\n",
      "(3464, 10) 3464\n"
     ]
    }
   ],
   "source": [
    "# set the ratio of goods to bads that you would like. This next line is the ratio of goods to bads that you want for modeling\n",
    "sample_ratio_desired = 1\n",
    "\n",
    "temp = X_trntst.copy()\n",
    "temp['Fraud'] = Y_trntst['Fraud']\n",
    "temp.head()\n",
    "goods = temp[temp['Fraud']==0]\n",
    "bads = temp[temp['Fraud']==1]\n",
    "actual_bad_fraction = len(bads)/len(temp)\n",
    "actual_good_fraction = 1 - actual_bad_fraction\n",
    "print(actual_bad_fraction)\n",
    "fraction = sample_ratio_desired * actual_bad_fraction\n",
    "goods_sampled = goods.sample(frac = fraction)\n",
    "all_sampled = pd.concat([goods_sampled,bads])\n",
    "all_sampled.sort_index(inplace=True)\n",
    "Y_trntst_sampled = pd.DataFrame(all_sampled['Fraud'])\n",
    "X_trntst_sampled = all_sampled.drop(columns=['Fraud'])\n",
    "del [temp,goods,bads,all_sampled]\n",
    "gc.collect()\n",
    "print(X_trntst_sampled.shape,len(Y_trntst_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We do a manual cross validation by running each model nitermax times for each choice of hyperparameters. The good\n",
    "# statistical measurement of the model performance is the average across all these nitermax runs.\n",
    "niter = 0\n",
    "nitermax = 10\n",
    "jittersize = .1\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment in/out any of these model cells and/or just explore one model type. You can also just rerun any single cell multiple times (hit shift-enter on that cell) as you \"manually\" explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modeling_output = pd.DataFrame(columns=['Model','Trn','Tst','OOT'],index=range(1000))\n",
    "counter = 0\n",
    "model_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6900247320692497 0.6573556797020484 0.46464646464646464\n",
      "1 0.683265306122449 0.6742857142857143 0.46464646464646464\n",
      "2 0.6727574750830565 0.6959706959706959 0.46464646464646464\n",
      "3 0.6814011676396997 0.6896551724137931 0.46464646464646464\n",
      "4 0.6737704918032786 0.6924528301886792 0.468013468013468\n",
      "5 0.6950122649223222 0.6584440227703985 0.468013468013468\n",
      "6 0.6843413421706711 0.6777163904235728 0.46464646464646464\n",
      "7 0.6824104234527687 0.6762452107279694 0.4612794612794613\n",
      "8 0.6942622950819672 0.6471698113207547 0.4713804713804714\n",
      "9 0.6782464846980976 0.6876155268022182 0.47474747474747475\n",
      "trn    0.683549\n",
      "tst    0.675691\n",
      "oot    0.466667\n",
      "dtype: float64\n",
      "CPU times: total: 54.8 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "\n",
    "FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear' ,  C=0.5, max_iter=150)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['log reg',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7844611528822055 0.7450271247739603 0.5757575757575758\n",
      "1 0.79766860949209 0.7377049180327869 0.5589225589225589\n",
      "2 0.7854889589905363 0.7302904564315352 0.5723905723905723\n",
      "3 0.7886977886977887 0.7391304347826086 0.494949494949495\n",
      "4 0.7771520514883347 0.7731755424063116 0.5925925925925926\n",
      "5 0.7841552142279709 0.7309941520467836 0.5757575757575758\n",
      "6 0.7893442622950819 0.7339622641509433 0.5387205387205387\n",
      "7 0.7784090909090909 0.7432432432432432 0.5723905723905723\n",
      "8 0.7777777777777778 0.7559055118110236 0.5555555555555556\n",
      "9 0.7833197056418643 0.7343453510436433 0.5555555555555556\n",
      "trn    0.784647\n",
      "tst    0.742378\n",
      "oot    0.559259\n",
      "dtype: float64\n",
      "CPU times: total: 3.28 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "\n",
    "FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = DecisionTreeClassifier(splitter='best',max_depth=10,min_samples_split=50,min_samples_leaf=25)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['DT',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "\n",
    "print(FDR.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7743221690590112 0.7358870967741935 0.494949494949495\n",
      "1 0.7735697018533441 0.75049115913556 0.5589225589225589\n",
      "2 0.7660626029654036 0.7444029850746269 0.5151515151515151\n",
      "3 0.7754098360655738 0.7264150943396226 0.5824915824915825\n",
      "4 0.7752255947497949 0.7419962335216572 0.5286195286195287\n",
      "5 0.7657004830917874 0.7618110236220472 0.5757575757575758\n",
      "6 0.7637407711238721 0.7532956685499058 0.5185185185185185\n",
      "7 0.779126213592233 0.7509727626459144 0.5151515151515151\n",
      "8 0.7738287560581584 0.71484375 0.5353535353535354\n",
      "9 0.7673060884070059 0.7332123411978222 0.5723905723905723\n",
      "trn    0.771429\n",
      "tst    0.741333\n",
      "oot    0.539731\n",
      "dtype: float64\n",
      "CPU times: total: 3min 41s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "\n",
    "FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100,max_depth=10,min_samples_split=80,min_samples_leaf=40,max_features=13)\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['RF',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Facundo\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Facundo\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1225, number of negative: 58459\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020525 -> initscore=-3.865385\n",
      "[LightGBM] [Info] Start training from score -3.865385\n",
      "0 0.7444897959183674 0.7561904761904762 0.5252525252525253\n",
      "[LightGBM] [Info] Number of positive: 1232, number of negative: 58452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020642 -> initscore=-3.859567\n",
      "[LightGBM] [Info] Start training from score -3.859567\n",
      "1 0.752435064935065 0.7741312741312741 0.5387205387205387\n",
      "[LightGBM] [Info] Number of positive: 1217, number of negative: 58467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020391 -> initscore=-3.872074\n",
      "[LightGBM] [Info] Start training from score -3.872074\n",
      "2 0.7485620377978636 0.7542213883677298 0.5656565656565656\n",
      "[LightGBM] [Info] Number of positive: 1253, number of negative: 58431\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020994 -> initscore=-3.842306\n",
      "[LightGBM] [Info] Start training from score -3.842306\n",
      "3 0.7446129289704708 0.7062374245472837 0.5353535353535354\n",
      "[LightGBM] [Info] Number of positive: 1219, number of negative: 58465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020424 -> initscore=-3.870397\n",
      "[LightGBM] [Info] Start training from score -3.870397\n",
      "4 0.7596390484003281 0.736346516007533 0.5252525252525253\n",
      "[LightGBM] [Info] Number of positive: 1219, number of negative: 58465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020424 -> initscore=-3.870397\n",
      "[LightGBM] [Info] Start training from score -3.870397\n",
      "5 0.7694831829368335 0.7419962335216572 0.5454545454545454\n",
      "[LightGBM] [Info] Number of positive: 1242, number of negative: 58442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020810 -> initscore=-3.851312\n",
      "[LightGBM] [Info] Start training from score -3.851312\n",
      "6 0.7592592592592593 0.7322834645669292 0.5656565656565656\n",
      "[LightGBM] [Info] Number of positive: 1217, number of negative: 58467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2081\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020391 -> initscore=-3.872074\n",
      "[LightGBM] [Info] Start training from score -3.872074\n",
      "7 0.7674609695973705 0.7467166979362101 0.5252525252525253\n",
      "[LightGBM] [Info] Number of positive: 1217, number of negative: 58467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020391 -> initscore=-3.872074\n",
      "[LightGBM] [Info] Start training from score -3.872074\n",
      "8 0.7551355792933443 0.7467166979362101 0.5589225589225589\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 58480\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2081\n",
      "[LightGBM] [Info] Number of data points in the train set: 59684, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020173 -> initscore=-3.883035\n",
      "[LightGBM] [Info] Start training from score -3.883035\n",
      "9 0.7624584717607974 0.7307692307692307 0.5420875420875421\n",
      "trn    0.756354\n",
      "tst    0.742561\n",
      "oot    0.542761\n",
      "dtype: float64\n",
      "CPU times: total: 19 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "\n",
    "FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators= 30, num_leaves= 5, max_depth= 3, min_child_samples= 60)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # LGBM with SMOTE\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):    \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "    \n",
    "#     sm = SMOTE()\n",
    "    \n",
    "#     X_trn_sm, Y_trn_sm = sm.fit_resample(X_trn,Y_trn)\n",
    "    \n",
    "#     print(niter, X_trn.shape,Y_trn.shape)\n",
    "#     print(niter, X_trn_sm.shape,Y_trn_sm.shape)\n",
    "#     print(Y_trn.sum())\n",
    "#     print(Y_trn_sm.sum())\n",
    "\n",
    "#     model = lgb.LGBMClassifier()\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn_sm, Y_trn_sm.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['LGBM with SMOTE',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # LGBM with jitter\n",
    "\n",
    "# jittersize = .1\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):    \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "    \n",
    "#     print(niter, X_trn.shape,Y_trn.shape)\n",
    "    \n",
    "#     X_trn_bads = X_trn[Y_trn == 1]\n",
    "#     Y_trn_bads = Y_trn[Y_trn == 1]\n",
    "    \n",
    "#     print(X_trn_bads.head())\n",
    "#     for i in range(2):\n",
    "#         X_trn_more = X_trn_bads*(1+jittersize*random.uniform(-1,1))\n",
    "#         X_trn = X_trn.append(X_trn_more,ignore_index=True)\n",
    "#         Y_trn = Y_trn.append(Y_trn_bads,ignore_index=True)\n",
    "        \n",
    "#     print(niter, X_trn.shape,Y_trn.shape)\n",
    "\n",
    "#     model = lgb.LGBMClassifier()\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['LGBM with jitter',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7908286403861625 0.7416173570019724 0.5016835016835017\n",
      "1 0.807258064516129 0.7607843137254902 0.5488215488215489\n",
      "2 0.7996702390766695 0.7411545623836127 0.5286195286195287\n",
      "3 0.7998338870431894 0.7490842490842491 0.5387205387205387\n",
      "4 0.794331983805668 0.7514563106796116 0.4612794612794613\n",
      "5 0.8128119800332779 0.7463503649635036 0.5016835016835017\n",
      "6 0.7938487115544473 0.7678244972577697 0.5218855218855218\n",
      "7 0.7960363336085879 0.7476808905380334 0.5252525252525253\n",
      "8 0.8057142857142857 0.7219047619047619 0.5185185185185185\n",
      "9 0.7936 0.724 0.5016835016835017\n",
      "trn    0.799393\n",
      "tst    0.745186\n",
      "oot    0.514815\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "\n",
    "FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "      \n",
    "    model = MLPClassifier(hidden_layer_sizes=(15,15,15,15),learning_rate_init=0.001, momentum=0.9)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['NN',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # NN on pc's\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_pca, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = MLPClassifier(hidden_layer_sizes=(20,))\n",
    "\n",
    "#     X_oot = X_oot_orig_pca.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['NN_PCs',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # GBC\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = GradientBoostingClassifier()\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['GBC',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7660098522167488 0.7744360902255639 0.5286195286195287\n",
      "1 0.7734187349879904 0.7544910179640718 0.4983164983164983\n",
      "2 0.7733664185277088 0.7338262476894639 0.5016835016835017\n",
      "3 0.7736928104575164 0.7585551330798479 0.5252525252525253\n",
      "4 0.7681274900398406 0.7777777777777778 0.4983164983164983\n",
      "5 0.7739888977002379 0.7464212678936605 0.494949494949495\n",
      "6 0.7701516360734237 0.7545271629778671 0.4983164983164983\n",
      "7 0.7772236076475478 0.7495429616087751 0.5084175084175084\n",
      "8 0.7688483844241922 0.7458563535911602 0.4983164983164983\n",
      "9 0.7629449838187702 0.7665369649805448 0.5050505050505051\n",
      "trn    0.770777\n",
      "tst    0.756197\n",
      "oot    0.505724\n",
      "dtype: float64\n",
      "CPU times: total: 3min 47s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Catboost\n",
    "\n",
    "FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(verbose=0,learning_rate=.02,l2_leaf_reg=3,depth=3,min_data_in_leaf=60)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # NOTE this cell has been substantially modified to evaluate a sampled trn/tst data set. \n",
    "# # Only use this cell if you do downsampling of the goods.\n",
    "# # each good needs to have a weight of (1-actual_ratio)/sample_ratio_desired\n",
    "# # it's hard to get the correct FDR@3% for the actual train and test, so I just use the original trntst after the model is built for evaluation\n",
    "\n",
    "# xmult = actual_good_fraction / (actual_bad_fraction * sample_ratio_desired)\n",
    "# print(xmult)\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_sampled, Y_trntst_sampled, test_size = .3)\n",
    "\n",
    "#     model = lgb.LGBMClassifier()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())  \n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn = X_trntst.copy()\n",
    "#     Y_trn = Y_trntst.copy()\n",
    "#     X_tst = X_trntst.copy()\n",
    "#     Y_tst = Y_trntst.copy()\n",
    "\n",
    "#     predictions = model.predict_proba(X_trntst)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trntst['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_trntst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_trntst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['LGBM sampled',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Catboost on pc's\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_pca, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = CatBoostClassifier()\n",
    "\n",
    "#     X_oot = X_oot_orig_pca.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['cat boost_PCs',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # unsupervised model using pc's. \n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_pca, Y_trntst, test_size = .3)\n",
    "\n",
    "#     X_oot = X_oot_orig_pca.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     pow = 2\n",
    "#     oop = 1/pow\n",
    "#     predictions = ((X_trn.abs()**pow).sum(axis=1))**oop\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = ((X_tst.abs()**pow).sum(axis=1))**oop\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = ((X_oot.abs()**pow).sum(axis=1))**oop\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['unsupervised outliers',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # XGB\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = xgb.XGBClassifier(booster='gbtree')\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['XGB',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Knn\n",
    "# # Knn can be very slow with a lot of records.\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "#     model = KNeighborsClassifier() \n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['Knn',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # SVM\n",
    "# # SVM can be very slow. It scales like the # training records cubed\n",
    "\n",
    "# FDR = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = svm.SVC(kernel='poly',probability=True)\n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['SVM',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.790829</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.501684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.807258</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.548822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.79967</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>0.52862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.799834</td>\n",
       "      <td>0.749084</td>\n",
       "      <td>0.538721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.794332</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.461279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.812812</td>\n",
       "      <td>0.74635</td>\n",
       "      <td>0.501684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.793849</td>\n",
       "      <td>0.767824</td>\n",
       "      <td>0.521886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.796036</td>\n",
       "      <td>0.747681</td>\n",
       "      <td>0.525253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.721905</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.7936</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.501684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.76601</td>\n",
       "      <td>0.774436</td>\n",
       "      <td>0.52862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.773419</td>\n",
       "      <td>0.754491</td>\n",
       "      <td>0.498316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.773366</td>\n",
       "      <td>0.733826</td>\n",
       "      <td>0.501684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.773693</td>\n",
       "      <td>0.758555</td>\n",
       "      <td>0.525253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.768127</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.498316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.773989</td>\n",
       "      <td>0.746421</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.770152</td>\n",
       "      <td>0.754527</td>\n",
       "      <td>0.498316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.777224</td>\n",
       "      <td>0.749543</td>\n",
       "      <td>0.508418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.768848</td>\n",
       "      <td>0.745856</td>\n",
       "      <td>0.498316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>cat boost</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model       Trn       Tst       OOT\n",
       "40         NN  0.790829  0.741617  0.501684\n",
       "41         NN  0.807258  0.760784  0.548822\n",
       "42         NN   0.79967  0.741155   0.52862\n",
       "43         NN  0.799834  0.749084  0.538721\n",
       "44         NN  0.794332  0.751456  0.461279\n",
       "45         NN  0.812812   0.74635  0.501684\n",
       "46         NN  0.793849  0.767824  0.521886\n",
       "47         NN  0.796036  0.747681  0.525253\n",
       "48         NN  0.805714  0.721905  0.518519\n",
       "49         NN    0.7936     0.724  0.501684\n",
       "50  cat boost   0.76601  0.774436   0.52862\n",
       "51  cat boost  0.773419  0.754491  0.498316\n",
       "52  cat boost  0.773366  0.733826  0.501684\n",
       "53  cat boost  0.773693  0.758555  0.525253\n",
       "54  cat boost  0.768127  0.777778  0.498316\n",
       "55  cat boost  0.773989  0.746421  0.494949\n",
       "56  cat boost  0.770152  0.754527  0.498316\n",
       "57  cat boost  0.777224  0.749543  0.508418\n",
       "58  cat boost  0.768848  0.745856  0.498316\n",
       "59  cat boost  0.762945  0.766537  0.505051"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.690025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.683265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.672757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.681401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.67377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.690025\n",
       "1  log reg  Trn  0.683265\n",
       "2  log reg  Trn  0.672757\n",
       "3  log reg  Trn  0.681401\n",
       "4  log reg  Trn   0.67377"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_unpivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.690025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.683265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.672757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.681401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.67377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.690025\n",
       "1  log reg  Trn  0.683265\n",
       "2  log reg  Trn  0.672757\n",
       "3  log reg  Trn  0.681401\n",
       "4  log reg  Trn   0.67377"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.784647</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.742378</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.756354</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>0.742561</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>0.542761</td>\n",
       "      <td>0.016014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.799393</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.745186</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.514815</td>\n",
       "      <td>0.024663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.741333</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>0.539731</td>\n",
       "      <td>0.030492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat boost</th>\n",
       "      <td>0.770777</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.756197</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.505724</td>\n",
       "      <td>0.011856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log reg</th>\n",
       "      <td>0.683549</td>\n",
       "      <td>0.007709</td>\n",
       "      <td>0.675691</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Trn                 Tst                 OOT          \n",
       "               mean       std      mean       std      mean       std\n",
       "Model                                                                \n",
       "DT         0.784647  0.006263  0.742378  0.013261  0.559259  0.027050\n",
       "LGBM       0.756354  0.008872  0.742561  0.018123  0.542761  0.016014\n",
       "NN         0.799393  0.007123  0.745186  0.014290  0.514815  0.024663\n",
       "RF         0.771429  0.005228  0.741333  0.014020  0.539731  0.030492\n",
       "cat boost  0.770777  0.004337  0.756197  0.013597  0.505724  0.011856\n",
       "log reg    0.683549  0.007709  0.675691  0.016610  0.466667  0.003952"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = df.groupby('Model').agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.690025</td>\n",
       "      <td>0.657356</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.683265</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.672757</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.681401</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>0.67377</td>\n",
       "      <td>0.692453</td>\n",
       "      <td>0.468013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model       Trn       Tst       OOT\n",
       "0  log reg  0.690025  0.657356  0.464646\n",
       "1  log reg  0.683265  0.674286  0.464646\n",
       "2  log reg  0.672757  0.695971  0.464646\n",
       "3  log reg  0.681401  0.689655  0.464646\n",
       "4  log reg   0.67377  0.692453  0.468013"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5925925925925926"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_OOT = df['OOT'].max()\n",
    "best_OOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "\n",
    "plt.ylim(.4,0.9)\n",
    "plt.ylabel('Score (FDR%)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:36:41.175076\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell can be used to explore overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7901929260450161 0.7529644268774703 0.5084175084175084\n",
      "1 0.7748123436196831 0.7531760435571688 0.5117845117845118\n",
      "2 0.7701056051990252 0.7707129094412332 0.531986531986532\n",
      "loop trn tst oot 3 0.7783702916212415 0.7589511266252907 0.5173961840628508\n",
      "0 0.7767068273092369 0.7445544554455445 0.49158249158249157\n",
      "1 0.7647540983606558 0.7716981132075472 0.4882154882154882\n",
      "2 0.751818916734034 0.7797270955165692 0.5016835016835017\n",
      "loop trn tst oot 4 0.7644266141346422 0.7653265547232203 0.49382716049382713\n",
      "0 0.7657370517928287 0.7656565656565657 0.4983164983164983\n",
      "1 0.7778681855166802 0.7485604606525912 0.49158249158249157\n",
      "2 0.7681744749596123 0.771484375 0.5286195286195287\n",
      "loop trn tst oot 5 0.7705932374230403 0.7619004671030524 0.5061728395061729\n",
      "0 0.7844408427876823 0.7461240310077519 0.48484848484848486\n",
      "1 0.7799196787148595 0.7702970297029703 0.5151515151515151\n",
      "2 0.7760330578512397 0.7685185185185185 0.5185185185185185\n",
      "loop trn tst oot 6 0.7801311931179272 0.7616465264097468 0.5061728395061729\n",
      "0 0.7590945836701698 0.7699805068226121 0.5050505050505051\n",
      "1 0.7900326797385621 0.7737642585551331 0.48148148148148145\n",
      "2 0.7939778129952456 0.7438524590163934 0.531986531986532\n",
      "loop trn tst oot 7 0.7810350254679924 0.7625324081313796 0.5061728395061729\n",
      "0 0.7868988391376451 0.7463235294117647 0.5084175084175084\n",
      "1 0.7792207792207793 0.752895752895753 0.5151515151515151\n",
      "2 0.7789389067524116 0.7490118577075099 0.5084175084175084\n",
      "loop trn tst oot 8 0.7816861750369454 0.7494103800050093 0.510662177328844\n",
      "0 0.7626977518734388 0.761384335154827 0.5117845117845118\n",
      "1 0.7750809061488673 0.7684824902723736 0.5252525252525253\n",
      "2 0.7578616352201258 0.7887029288702929 0.4983164983164983\n",
      "loop trn tst oot 9 0.7652134310808106 0.7728565847658312 0.5117845117845118\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell is used only to examine overfitting for any particular model type.\n",
    "# One can iterate through a hyperparameter's value, either increasing or decreasing it, and watching the overfitting.\n",
    "nitermax2 = 3 # Lower the number of model builds for each value of hyperparameters so this cell runs faster.\n",
    "training = []\n",
    "testing = []\n",
    "oot = []\n",
    "results = pd.DataFrame(np.zeros((niter,3)),columns=['trn','tst','oot'])\n",
    "\n",
    "# Here's where we set theÂ manner of the hyperparameter's ranga and increment.\n",
    "for i in range(3,10,1):\n",
    "\n",
    "# Now just run the model as before.\n",
    "    for niter in range(nitermax2):\n",
    "        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "  \n",
    "        io2 = int(i/2) # the min_samples_leaf can be set to half the min_samples_split for simplicity.\n",
    "        model = CatBoostClassifier(verbose=0,learning_rate=.02,l2_leaf_reg=3,depth=3,min_data_in_leaf=60)\n",
    "\n",
    "        model.fit(X_trn, Y_trn.values.ravel()) \n",
    "\n",
    "        X_oot = X_oot_orig.copy()\n",
    "        X_trn_save = X_trn.copy()\n",
    "        Y_trn_save = Y_trn.copy()\n",
    "    \n",
    "        predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "        X_trn['predicted'] = predictions\n",
    "        X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "        topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "        temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "        needed = temp.loc[:,'Fraud']\n",
    "        results.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "        predictions = model.predict_proba(X_tst)[:,1]\n",
    "        X_tst['predicted']=predictions\n",
    "        X_tst['Fraud'] = Y_tst['Fraud']\n",
    "        topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "        temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "        needed = temp.loc[:,'Fraud']\n",
    "        results.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "        predictions = model.predict_proba(X_oot)[:,1]\n",
    "        X_oot['predicted']=predictions\n",
    "        X_oot['Fraud'] = Y_oot['Fraud']\n",
    "        topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "        temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "        needed = temp.loc[:,'Fraud']\n",
    "        results.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "        print(niter, results.loc[niter,'trn'],results.loc[niter,'tst'],results.loc[niter,'oot'],)\n",
    "\n",
    "    results_mean_trn = results['trn'].mean()\n",
    "    results_mean_tst = results['tst'].mean()\n",
    "    results_mean_oot = results['oot'].mean()\n",
    "    print('loop', 'trn', 'tst', 'oot', i, results_mean_trn, results_mean_tst, results_mean_oot)\n",
    "    training.append(results_mean_trn)\n",
    "    testing.append(results_mean_tst)\n",
    "    oot.append(results_mean_oot)\n",
    "\n",
    "table=pd.DataFrame({'n': range(1,len(training)+1),'training':training,'testing':testing,'oot':oot})\n",
    "table.set_index('n',inplace=True) \n",
    "table.plot()\n",
    "plt.savefig('complexity_NN.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_OOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like (due to the stochastic nature of some ML algorithms, but you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Note - need to set this next value to around the highest oot fdr for your model of choice.\n",
    "# The model then runs a nombermof times with your fixed hyperparameters until it finds a good model.\n",
    "desire = .55\n",
    "print('desire =', desire)\n",
    "for niter in range(50):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "# Here's where you put your final model of choice.\n",
    "# I run this loop a large number of times with an unreasonably high stopping criterion (the break condition)\n",
    "# I then look at all these runs and select a value of the oot performance where I want to break out this loop\n",
    "# and that will be my final model run of choice.\n",
    "    model = lgb.LGBMClassifier()\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*detect_rate))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*detect_rate))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*detect_rate))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR.loc[niter, 'trn'],FDR.loc[niter, 'tst'],FDR.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "# choose a good break point\n",
    "    if(FDR.loc[niter, 'oot'] > desire): break\n",
    "    \n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = X_trn.copy()\n",
    "X_tst_eval = X_tst.copy()\n",
    "X_oot_eval = X_oot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "bad_tot_trn = sum(X_trn_eval.loc[:, 'Fraud'])\n",
    "bad_tot_tst = sum(X_tst_eval.loc[:, 'Fraud'])\n",
    "bad_tot_oot = sum(X_oot_eval.loc[:, 'Fraud'])\n",
    "num_tot_trn = len(X_trn_eval)\n",
    "num_tot_tst = len(X_tst_eval)\n",
    "num_tot_oot = len(X_oot_eval)\n",
    "good_tot_trn = num_tot_trn - bad_tot_trn\n",
    "good_tot_tst = num_tot_tst - bad_tot_tst\n",
    "good_tot_oot = num_tot_oot - bad_tot_oot\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fraud = 400\n",
    "cost_fp = 20\n",
    "for i in range(101):\n",
    "    percent_rows_trn = int(round(X_trn_eval.shape[0]*0.01*i))\n",
    "    percent_rows_tst = int(round(X_tst_eval.shape[0]*0.01*i))\n",
    "    percent_rows_oot = int(round(X_oot_eval.shape[0]*0.01*i))\n",
    "    temp_trn = trn_sorted.head(percent_rows_trn)\n",
    "    temp_tst = tst_sorted.head(percent_rows_tst)\n",
    "    temp_oot = oot_sorted.head(percent_rows_oot)\n",
    "    num_bad_trn = sum(temp_trn.loc[:,'Fraud'])\n",
    "    num_bad_tst = sum(temp_tst.loc[:,'Fraud'])\n",
    "    num_bad_oot = sum(temp_oot.loc[:,'Fraud'])\n",
    "    num_tot_trn = len(temp_trn)\n",
    "    num_tot_tst = len(temp_tst)\n",
    "    num_tot_oot = len(temp_oot)\n",
    "    num_good_trn = num_tot_trn - num_bad_trn\n",
    "    num_good_tst = num_tot_tst - num_bad_tst\n",
    "    num_good_oot = num_tot_oot - num_bad_oot\n",
    "    \n",
    "    FDR_trn.loc[i, 'bin'] = i\n",
    "    FDR_trn.loc[i,'#recs'] = 0\n",
    "    FDR_trn.loc[i, 'tot'] = num_tot_trn\n",
    "    FDR_trn.loc[i, 'cg'] = num_good_trn\n",
    "    FDR_trn.loc[i, 'cb'] = num_bad_trn\n",
    "    FDR_trn.loc[i, 'Fraud Savings'] = FDR_trn.loc[i, 'cb'] * cost_fraud\n",
    "    FDR_trn.loc[i, 'FP Loss'] = FDR_trn.loc[i, 'cg'] * cost_fp\n",
    "    FDR_trn.loc[i, 'Overall Savings'] = FDR_trn.loc[i, 'Fraud Savings'] - FDR_trn.loc[i, 'FP Loss']\n",
    "    FDR_tst.loc[i, 'bin'] = i\n",
    "    FDR_tst.loc[i, 'tot'] = num_tot_tst\n",
    "    FDR_tst.loc[i, 'cg'] = num_good_tst\n",
    "    FDR_tst.loc[i, 'cb'] = num_bad_tst\n",
    "    FDR_tst.loc[i, 'Fraud Savings'] = FDR_tst.loc[i, 'cb'] * cost_fraud\n",
    "    FDR_tst.loc[i, 'FP Loss'] = FDR_tst.loc[i, 'cg'] * cost_fp\n",
    "    FDR_tst.loc[i, 'Overall Savings'] = FDR_tst.loc[i, 'Fraud Savings'] - FDR_tst.loc[i, 'FP Loss']\n",
    "    FDR_oot.loc[i, 'bin'] = i\n",
    "    FDR_oot.loc[i, 'tot'] = num_tot_oot\n",
    "    FDR_oot.loc[i, 'cg'] = num_good_oot\n",
    "    FDR_oot.loc[i, 'cb'] = num_bad_oot\n",
    "\n",
    "    if i != 0:\n",
    "        FDR_trn.loc[i, '#g'] = num_good_trn - FDR_trn.loc[i-1, 'cg']\n",
    "        FDR_trn.loc[i, '#b'] = num_bad_trn - FDR_trn.loc[i-1, 'cb']\n",
    "        FDR_trn.loc[i,'#recs'] = FDR_trn.loc[i, '#g'] + FDR_trn.loc[i, '#b']\n",
    "        FDR_trn.loc[i, '%g'] = 100* (num_good_trn - FDR_trn.loc[i-1, 'cg']) / (num_tot_trn - FDR_trn.loc[i-1, 'tot'])\n",
    "        FDR_trn.loc[i, '%b'] = 100 - FDR_trn.loc[i, '%g']\n",
    "        FDR_trn.loc[i, '%cg'] = 100 * num_good_trn / good_tot_trn\n",
    "        FDR_trn.loc[i, 'FDR'] = 100 * num_bad_trn / bad_tot_trn\n",
    "        FDR_trn.loc[i, 'KS'] = FDR_trn.loc[i, 'FDR'] - FDR_trn.loc[i, '%cg']\n",
    "        FDR_trn.loc[i, 'FPR'] = num_good_trn / num_bad_trn\n",
    "        FDR_tst.loc[i, '#g'] = num_good_tst - FDR_tst.loc[i-1, 'cg']\n",
    "        FDR_tst.loc[i, '#b'] = num_bad_tst - FDR_tst.loc[i-1, 'cb']\n",
    "        FDR_tst.loc[i,'#recs'] = FDR_tst.loc[i, '#g'] + FDR_tst.loc[i, '#b']\n",
    "        FDR_tst.loc[i, '%g'] = 100* (num_good_tst - FDR_tst.loc[i-1, 'cg']) / (num_tot_tst - FDR_tst.loc[i-1, 'tot'])\n",
    "        FDR_tst.loc[i, '%b'] = 100 - FDR_tst.loc[i, '%g']\n",
    "        FDR_tst.loc[i, '%cg'] = 100 * num_good_tst / good_tot_tst\n",
    "        FDR_tst.loc[i, 'FDR'] = 100 * num_bad_tst / bad_tot_tst\n",
    "        FDR_tst.loc[i, 'KS'] = FDR_tst.loc[i, 'FDR'] - FDR_tst.loc[i, '%cg']\n",
    "        FDR_tst.loc[i, 'FPR'] = num_good_tst / num_bad_tst\n",
    "        FDR_oot.loc[i, '#g'] = num_good_oot - FDR_oot.loc[i-1, 'cg']\n",
    "        FDR_oot.loc[i, '#b'] = num_bad_oot - FDR_oot.loc[i-1, 'cb']\n",
    "        FDR_oot.loc[i,'#recs'] = FDR_oot.loc[i, '#g'] + FDR_oot.loc[i, '#b']\n",
    "        FDR_oot.loc[i, '%g'] = 100* (num_good_oot - FDR_oot.loc[i-1, 'cg']) / (num_tot_oot - FDR_oot.loc[i-1, 'tot'])\n",
    "        FDR_oot.loc[i, '%b'] = 100 - FDR_oot.loc[i, '%g']\n",
    "        FDR_oot.loc[i, '%cg'] = 100 * num_good_oot / good_tot_oot\n",
    "        FDR_oot.loc[i, 'FDR'] = 100 * num_bad_oot / bad_tot_oot\n",
    "        FDR_oot.loc[i, 'KS'] = FDR_oot.loc[i, 'FDR'] - FDR_oot.loc[i, '%cg']\n",
    "        FDR_oot.loc[i, 'FPR'] = num_good_oot / num_bad_oot\n",
    "\n",
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# xmult: oot is only 2 out of 12 months. 100,000 sample transactions out of 10 million/year\n",
    "xoot = 12/2 * 10000000/100000\n",
    "Financials_trn = pd.DataFrame(np.zeros((101, 3)), columns = ['Fraud Savings','FP Loss','Overall Savings'])\n",
    "Financials_tst = pd.DataFrame(np.zeros((101, 3)), columns = ['Fraud Savings','FP Loss','Overall Savings'])\n",
    "Financials_oot = pd.DataFrame(np.zeros((101, 3)), columns = ['Fraud Savings','FP Loss','Overall Savings'])\n",
    "for i in range(101):\n",
    "    Financials_trn.loc[i, 'Fraud Savings'] = FDR_trn.loc[i, 'cb'] * cost_fraud * xoot\n",
    "    Financials_trn.loc[i, 'FP Loss'] = FDR_trn.loc[i, 'cg'] * cost_fp * xoot\n",
    "    Financials_trn.loc[i, 'Overall Savings'] = Financials_trn.loc[i, 'Fraud Savings'] - Financials_trn.loc[i, 'FP Loss']\n",
    "    Financials_tst.loc[i, 'Fraud Savings'] = FDR_tst.loc[i, 'cb'] * cost_fraud * xoot\n",
    "    Financials_tst.loc[i, 'FP Loss'] = FDR_tst.loc[i, 'cg'] * cost_fp * xoot\n",
    "    Financials_tst.loc[i, 'Overall Savings'] = Financials_tst.loc[i, 'Fraud Savings'] - Financials_tst.loc[i, 'FP Loss']\n",
    "    Financials_oot.loc[i, 'Fraud Savings'] = FDR_oot.loc[i, 'cb'] * cost_fraud * xoot\n",
    "    Financials_oot.loc[i, 'FP Loss'] = FDR_oot.loc[i, 'cg'] * cost_fp * xoot\n",
    "    Financials_oot.loc[i, 'Overall Savings'] = Financials_oot.loc[i, 'Fraud Savings'] - Financials_oot.loc[i, 'FP Loss']\n",
    "\n",
    "max_savings = Financials_oot['Overall Savings'].max(0)\n",
    "print('Max possible savings: '+'{:,}'.format(max_savings))\n",
    "yupper = max_savings * 1.5\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(Financials_oot['Fraud Savings'], color='green')\n",
    "plt.plot(Financials_oot['FP Loss'], color='red')\n",
    "plt.plot(Financials_oot['Overall Savings'], color='blue')\n",
    "xlimit = 20\n",
    "interval = 1\n",
    "plt.xlim(0,xlimit)\n",
    "plt.ylim(0,yupper)\n",
    "plt.xticks(ticks=np.linspace(0,xlimit, num=int(xlimit/interval)+1))\n",
    "plt.ticklabel_format(style='plain')\n",
    "plt.savefig('savings.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_oot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR.to_csv('FDR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics = FDR_oot.copy()\n",
    "num_good = Metrics['#g'].sum()\n",
    "num_bad = Metrics['#b'].sum()\n",
    "num_tot = Metrics['#recs'].sum()\n",
    "print(num_good,num_bad,num_good+num_bad,num_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics['TP'] = Metrics['cb']\n",
    "Metrics['TN'] = num_good - Metrics['cg']\n",
    "Metrics['FN'] = num_bad - Metrics['cb']\n",
    "Metrics['FP'] = Metrics['cg']\n",
    "Metrics['Accuracy'] = (Metrics['TP'] + Metrics['TN']) / num_tot\n",
    "Metrics['Misclass'] = (Metrics['FP'] + Metrics['FN']) / num_tot\n",
    "Metrics['FPRate'] = Metrics['FP'] / (Metrics['FP'] + Metrics['TN'])\n",
    "Metrics['FPRatio'] = Metrics['FP'] / Metrics['TP']\n",
    "Metrics['TPR'] = Metrics['TP'] / (Metrics['TP'] + Metrics['FN'])\n",
    "Metrics['TNR'] = Metrics['TN'] / (Metrics['TN'] + Metrics['FP'])\n",
    "Metrics['Precision'] = Metrics['TP'] / (Metrics['TP'] + Metrics['FP'])\n",
    "Metrics['f1'] = 2 * Metrics['Precision'] * Metrics['TPR'] / (Metrics['Precision'] + Metrics['TPR'])\n",
    "Metrics.to_csv('Metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':10})\n",
    "plt.plot(Metrics['bin'], Metrics['TPR'])\n",
    "plt.title('Fraud Detection Rate', fontsize=20)\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Score cutoff %', fontsize=15)\n",
    "plt.ylabel('FDR', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a highly imbalanced problem the # goods in each bin is close to constant except for the first few bins, so the FDR curve (xaxis is bin #) and the ROC (x axis is FP, which is # goods below the cutoff) look very similar. They're only different in the first few bins where the # goods are not ~constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Metrics['FPRate'], Metrics['TPR'])\n",
    "plt.title('ROC', fontsize=20)\n",
    "plt.xlabel('FPRate',fontsize=15)\n",
    "plt.ylabel('TPRate', fontsize=15)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('card transactions.csv')\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df[df['Transtype'] == 'P']\n",
    "df = df[df['Amount'] <= 3000000]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scale = 1/df['prediction'].max()\n",
    "df['prediction'] = df['prediction']*pred_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['prediction'],ascending=False)\n",
    "df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we're going to look at specific cards or merchants to look at the dynamics of the fraud score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = df[df['Fraud']==1]\n",
    "bads['Cardnum'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bads['Merchnum'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = 5142140316\n",
    "# card = 5142847398\n",
    "# card = 5142199009\n",
    "# card = 5142160778\n",
    "# card = 5142189341\n",
    "# card = 5142181728\n",
    "# card = 5142212038\n",
    "# card = 5142220919\n",
    "# card = 5142214614\n",
    "# card = 5142202847\n",
    "# card = 5142138135\n",
    "# card = 5142271065\n",
    "# card = 5142152857\n",
    "# card = 5142179617\n",
    "# card = 5142235211\n",
    "# card = 5142197711\n",
    "# card = 5142182128\n",
    "# card = 5142189113\n",
    "# card = 5142197563 \n",
    "\n",
    "merch = 4353000719908\n",
    "# merch = 930090121224  \n",
    "# merch = 48834000695423\n",
    "# merch = 44503738417400\n",
    "# merch = 44620009957157\n",
    "# merch = 4618901687330\n",
    "# merch = 4900009045549\n",
    "# merch = 49108234610000\n",
    "# merch = 4253052983001\n",
    "# merch = 4938909877224\n",
    "# merch = 44503082476300\n",
    "# merch = 46006333528866\n",
    "# merch = 4997674930332\n",
    "# merch = 46070095870009\n",
    "# merch = 49900020006406\n",
    "sample = df[df['Cardnum'] == card]\n",
    "# sample = df[df['Merchnum'] == str(merch)]\n",
    "sample['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.plot(sample['Date'],sample['prediction'])\n",
    "plt.plot_date(sample['Date'],sample['Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsample = sample[sample['Date'] > '2010-08-01']\n",
    "tsample = tsample[tsample['Date'] < '2010-09-10']\n",
    "tsample.reset_index(inplace=True)\n",
    "tsample.reset_index(inplace=True)\n",
    "tsample.rename(columns={'level_0':'counter'},inplace=True)\n",
    "tsample['counter'] = tsample['counter']+1\n",
    "tsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.plot(tsample['Date'],tsample['prediction'])\n",
    "plt.plot_date(tsample['Date'],tsample['Fraud'])\n",
    "plt.savefig('dynamics_time.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.plot(tsample['counter'],tsample['prediction'])\n",
    "plt.scatter(tsample['counter'],tsample['Fraud'])\n",
    "plt.savefig('dynamics_count.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsample.to_csv('dynamics_transactions.csv')\n",
    "tsample.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 600\n",
    "delta = 20\n",
    "odds_at_base = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_trn_eval,X_tst_eval,X_oot_eval])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = df.iloc[:,df.shape[1]-2:]\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=True)\n",
    "calib = calib.sort_values('predicted')\n",
    "calib.rename(columns={'predicted':'score_raw'}, inplace=True)\n",
    "calib['score_raw'].clip(upper=.999, inplace=True)\n",
    "calib['score_raw'].clip(lower=.00001, inplace=True)\n",
    "calib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(calib['score_raw'],bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason we bin the records is to calculate the odds. We can then find the relationship between the raw score and the log odds.\n",
    "nbins=100\n",
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','score_raw','prob(%)','odds','log_odds', 'log_odds_adj']\n",
    "cal_bins = pd.DataFrame(np.zeros((nbins+1, 14)), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tot = sum(calib.loc[:, 'Fraud'])\n",
    "good_tot = len(calib) - bad_tot\n",
    "print(bad_tot, good_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 1/nbins\n",
    "nrecs = calib.shape[0]\n",
    "cal_bins.loc[0,'log_odds_adj'] = -8\n",
    "for i in range(nbins+1):\n",
    "    percent_rows_top = int(round(nrecs*frac*i))\n",
    "    percent_rows_bottom = max(int(round(nrecs*frac*(i-1))),0)\n",
    "    temp = calib.iloc[percent_rows_bottom:percent_rows_top,:]\n",
    "    cal_bins.loc[i, 'score_raw'] = temp['score_raw'].mean()\n",
    "    num_bad = int(sum(temp.loc[:,'Fraud']))\n",
    "    num_tot = len(temp) * i\n",
    "    num_good = int(num_tot - num_bad)\n",
    "    cal_bins.loc[i, 'bin'] = i\n",
    "    cal_bins.loc[i,'#recs'] = 0\n",
    "    cal_bins.loc[i, 'tot'] = num_tot\n",
    "    cal_bins.loc[i, 'cg'] = num_good\n",
    "    cal_bins.loc[i, 'cb'] = num_bad\n",
    "    if i != 0:\n",
    "        cal_bins.loc[i, '#recs'] = len(temp)\n",
    "        cal_bins.loc[i, '#b'] = int(sum(temp.loc[:, 'Fraud']))\n",
    "        cal_bins.loc[i, '#g'] = cal_bins.loc[i, '#recs'] - cal_bins.loc[i, '#b']\n",
    "        cal_bins.loc[i, '%g'] = 100* cal_bins.loc[i, '#g'] / cal_bins.loc[i, '#recs']\n",
    "        cal_bins.loc[i, '%b'] = 100 - cal_bins.loc[i, '%g']\n",
    "        cal_bins.loc[i, 'cg'] = cal_bins.loc[i-1, 'cg'] + cal_bins.loc[i, '#g']\n",
    "        cal_bins.loc[i, 'cb'] = cal_bins.loc[i-1, 'cb'] + cal_bins.loc[i, '#b']\n",
    "        cal_bins.loc[i, 'prob(%)'] = 100 * cal_bins.loc[i, '#b'] / cal_bins.loc[i, '#recs']\n",
    "        cal_bins.loc[i, 'odds'] = (cal_bins.loc[i, '#b'] + .001) / cal_bins.loc[i, '#g']\n",
    "        cal_bins.loc[i, 'log_odds'] = np.log2(cal_bins.loc[i, 'odds'])\n",
    "        cal_bins.loc[i, 'log_odds_adj'] = max(cal_bins.loc[i, 'log_odds'], cal_bins.loc[i-1, 'log_odds_adj'])\n",
    "        \n",
    "cal_bins.drop(index=0,axis=0,inplace=True)\n",
    "cal_bins.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_bins.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.ylim([-6,5])\n",
    "plt.plot(cal_bins['score_raw'],cal_bins['log_odds'])\n",
    "# plt.plot(cal_bins['score_raw'],cal_bins['log_odds_adj'])\n",
    "# plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcg(x, a, b, c):\n",
    "    return c + b/(1 + np.exp(-a * x))\n",
    "\n",
    "def funcf(x, a, b, c):\n",
    "    return -np.log(-1 + b/(x - c))/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "popt, pcov = curve_fit(funcg, cal_bins['log_odds_adj'],cal_bins['score_raw'])   \n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(cal_bins['log_odds'],cal_bins['score'])\n",
    "plt.plot(cal_bins['log_odds_adj'],cal_bins['score_raw'])\n",
    "plt.plot(cal_bins['log_odds_adj'],funcg(cal_bins['log_odds_adj'], *popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the smooth curve fit to see if it's OK.\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(cal_bins['score_raw'], cal_bins['log_odds_adj'])\n",
    "plt.plot(cal_bins['score_raw'], funcf(cal_bins['score_raw'], *popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fit looks pretty good\n",
    "cal_bins['fit'] = funcf(cal_bins['score_raw'], *popt)\n",
    "cal_bins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the calibrated score\n",
    "cal_bins['score_calib'] = base + delta * cal_bins['fit'] - delta * np.log2(odds_at_base)\n",
    "cal_bins['score_calib'].fillna(999, inplace=True)\n",
    "cal_bins['score_calib'].clip(upper=999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "cal_bins.to_csv('cal_bins.csv')\n",
    "cal_bins.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib['score_calib'] = base - delta * np.log2(odds_at_base) + delta * funcg(calib['score_raw'], *popt)\n",
    "calib['score_calib'].fillna(999, inplace=True)\n",
    "calib['score_calib'].clip(upper=999, inplace=True)\n",
    "calib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nbins=100\n",
    "plt.hist(calib['score_raw'],bins=nbins)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(calib['score_calib'],bins=nbins)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods = calib[calib['Fraud']==0]\n",
    "bads = calib[calib['Fraud']==1]\n",
    "plt.hist(goods['score_raw'],bins = nbins, alpha = .5)\n",
    "plt.hist(bads['score_raw'],bins = nbins, alpha = .5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(goods['score_calib'],bins = nbins, alpha = .5)\n",
    "plt.hist(bads['score_calib'],bins = nbins, alpha = .5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
